import time

# The json import is no longer needed
from patchright.sync_api import sync_playwright, Playwright


def run(playwright: Playwright):
    """
    Launches a browser using patchright, solves the challenge, captures headers,
    and exports them to a usable Python file (base_headers.py).
    """
    context = playwright.chromium.launch_persistent_context(
        "USER_DATA_DIR",
        headless=False,
        channel="chrome",
        args=[
            "--no-first-run",
            "--no-service-autorun",
            "--password-store=basic",
            "--disable-features=IsolateOrigins,site-per-process",
        ],
        no_viewport=True,
    )

    page = context.new_page()

    print("Navigating to https://www.idealista.com/...")

    try:
        page.goto("https://www.idealista.com/inmueble/94726991/", timeout=60000)

        print("\n--- ACTION REQUIRED ---")
        print(
            "The browser has opened. Please solve the Datadome challenge (e.g., click and hold the button)."
        )
        print("The script will wait for you to complete it...")

        datadome_cookie = None
        for _ in range(120):
            cookies = context.cookies()
            for cookie in cookies:
                if cookie["name"] == "datadome":
                    datadome_cookie = cookie
                    break
            if datadome_cookie:
                break
            time.sleep(1)

        if datadome_cookie:
            print("\n✅ Datadome challenge solved successfully!")
            print("Datadome Cookie Found:")
            print(f"   Value: {datadome_cookie['value']}")

            print("\nCapturing headers from an authenticated request...")
            captured_headers = {}

            def capture_request_headers(request):
                if (
                    request.is_navigation_request()
                    and request.resource_type == "document"
                ):
                    captured_headers.update(request.headers)

            page.on("request", capture_request_headers)
            page.reload(wait_until="networkidle")
            page.remove_listener("request", capture_request_headers)

            if not captured_headers:
                raise RuntimeError("Failed to capture headers on the second request.")

            all_cookies = context.cookies()
            captured_headers["cookie"] = "; ".join(
                [f"{c['name']}={c['value']}" for c in all_cookies]
            )

            headers_to_remove = ["host", "connection", "content-length"]
            for h in headers_to_remove:
                captured_headers.pop(h, None)

            print("✅ Headers captured.")

            # --- START: EXPORT TO PYTHON FILE ---
            try:
                # Build the content for the .py file as a list of strings
                py_file_lines = [
                    "# Establish persistent HTTPX session with browser-like headers to avoid blocking\n",
                    "# Generated by the scraping script.\n\n",
                    "BASE_HEADERS = {\n",
                ]

                # Add each header as a key-value pair
                for key, value in captured_headers.items():
                    # Use repr(value) to ensure the value is a valid, escaped Python string
                    py_file_lines.append(f'    "{key}": {repr(value)},\n')

                py_file_lines.append("}\n\n")
                py_file_lines.append(
                    "# Note: The header values are dynamic and will be updated each time the script is run.\n"
                )

                # Write the content to base_headers.py
                with open("base_headers.py", "w", encoding="utf-8") as f:
                    f.writelines(py_file_lines)

                print("✅ Python dictionary exported to base_headers.py.")
            except Exception as e:
                print(f"❌ Failed to export headers to Python file: {e}")
            # --- END: EXPORT TO PYTHON FILE ---

        else:
            print(
                "\n❌ Timed out waiting for the Datadome cookie. Please try running the script again."
            )

    except Exception as e:
        print(f"An error occurred: {e}")

    finally:
        print("\nClosing the browser in 10 seconds...")
        time.sleep(10)
        context.close()


# --- Main execution block ---
if __name__ == "__main__":
    with sync_playwright() as playwright:
        run(playwright)
