[![en](https://img.shields.io/badge/lang-en-red.svg)](https://github.com/maiktreya/rental-scrapers/blob/main/readme.md)
[![es](https://img.shields.io/badge/lang-es-yellow.svg)](https://github.com/maiktreya/rental-scrapers/blob/main/readme.es.md)

---

# üè† Scrapers de Alquiler para el Empoderamiento de Inquilinas

Este proyecto est√° dise√±ado para empoderar a los inquilinos y usuarios a peque√±a escala proporcionando scrapers accesibles para listados de propiedades en Airbnb e Idealista. Con el aumento de los precios de la vivienda y pr√°cticas de alquiler injustas, el acceso a los datos es crucial. Esta herramienta permite a los individuos recopilar datos sobre propiedades disponibles sin estar sujetos a pr√°cticas opacas basadas en anuncios.

**Nota:** No est√° destinado para su uso a escala corporativa ni para explotar los datos de propiedades a gran escala. Los scrapers est√°n dise√±ados para **uso personal**, centr√°ndose en el derecho a la informaci√≥n para los inquilinos.

## ‚öôÔ∏è Instalaci√≥n

Para los no expertos, aqu√≠ tienes una forma sencilla de comenzar con un entorno virtual de Python:

1. **Instalar Python:** Aseg√∫rate de tener [Python 3.7+](https://www.python.org/downloads/) instalado en tu equipo.

2. **Crear un entorno virtual:**

   En el directorio ra√≠z del proyecto (donde se encuentra este archivo README), ejecuta los siguientes comandos para crear y activar un entorno virtual llamado `env`:

   ```bash
   python -m venv env
   source env/bin/activate  # En Windows usar: .\env\Scripts\activate
   ```

3. **Instalar las dependencias requeridas:**

   Una vez activado el entorno virtual, instala los paquetes necesarios ejecutando:

   ```bash
   pip install -r requirements.txt
   ```

¬°Ahora tu entorno est√° listo para ejecutar los scrapers!

## üéØ Objetivo del Proyecto

El objetivo de este proyecto es empoderar a las personas afectadas por el aumento de los costos de vivienda, ofreci√©ndoles una forma f√°cil de acceder a listados p√∫blicos de propiedades y hacer el mercado de alquiler m√°s transparente. Simplifica el scraping sin las complejidades corporativas (como las solicitudes paralelas o proxies), manteni√©ndose enfocado en usos personales y a peque√±a escala.

## üõ†Ô∏è Funcionalidades Clave

- Scrapea listados de Airbnb (corto, medio y largo plazo).
- Scrapea listados de propiedades de Idealista tanto de venta como de alquiler.
- Maneja la paginaci√≥n y guarda los datos en formato CSV o JSON.
- Soporta retrasos personalizables para evitar bloqueos.
- Enfoque simple y minimalista adaptado a usuarios personales.

## üöÄ Uso

### Requisitos Previos

- Python 3.7+
- ChromeDriver para scraping de Airbnb (a trav√©s de Selenium)
- Entorno virtual con los paquetes requeridos (`httpx`, `selenium`, `parsel`, `argparse`, `pandas`, `beautifulsoup4`)

### Ejecutar el Scraper de Airbnb

Para scrapear listados de Airbnb:

```bash
python src/airbnb_scraper.py --url "AIRBNB_URL" --format csv
```

### Ejecutar el Scraper de Idealista

Para scrapear listados de Idealista:

```bash
python src/idealista_scraper.py --url "IDEALISTA_URL" --delay 2 --format csb
```

### Ejecutar Todos los Scrapers

Puedes ejecutar todos los scrapers usando el script Bash proporcionado:

```bash
bash src/run_scraper.sh
```

### Resultados

Los datos scrapeados se guardar√°n en el directorio `out/` en formatos JSON y CSV.

Puedes crear un cron job en Ubuntu para ejecutar tu scraper de Python diariamente a las 2:00 AM siguiendo estos pasos:

1. **Abrir el archivo crontab para editarlo:**

   Abre la terminal y escribe:

   ```bash
   crontab -e
   ```

2. **A√±adir el cron job:**

   En el editor que se abre, a√±ade la siguiente l√≠nea (donde path es la ruta al directorio rental-scrapers):

   ```bash
   0 2 * * * $PATH/rental-scrapers/src/run_scraper.sh >> $PATH/rental-scrapers/out/scraper.log 2>&1
   ```

   - `0 2 * * *` establece el cron job para que se ejecute diariamente a las 2:00 AM.
   - `/usr/bin/python3` es la ruta al int√©rprete de Python 3. Si est√°s usando un entorno virtual, aseg√∫rate de actualizar esta ruta.
   - `>> $PATH/rental-scrapers/out/scraper.log 2>&1` asegura que tanto la salida como cualquier error se registren en un archivo log.

3. **Guardar y salir:**

   Despu√©s de a√±adir la l√≠nea, guarda el archivo y sal del editor. Ahora tu cron job se ejecutar√° diariamente a las 2:00 AM.

Aseg√∫rate de que tu script sea ejecutable y que todos los permisos necesarios est√©n correctamente configurados. Tambi√©n recuerda modificar la variable $BASE_PATH en el script run_scraper.sh por la ruta local adecuada.

---

## üíº Aviso Legal

Esta herramienta se proporciona √∫nicamente para uso personal y con fines informativos. Est√° destinada a dar acceso justo a los datos de vivienda a los usuarios a peque√±a escala. Los desarrolladores no son responsables del mal uso de esta herramienta ni de las consecuencias legales que puedan surgir por realizar scraping a gran escala o con fines comerciales. Los usuarios deben asegurarse de cumplir con los t√©rminos de servicio de los sitios web que scrapean.

## üîí Licencia

Este proyecto est√° licenciado bajo la Licencia P√∫blica General de GNU (GPL-3). Consulta la licencia completa [aqu√≠](https://www.gnu.org/licenses/gpl-3.0.en.html).

---
